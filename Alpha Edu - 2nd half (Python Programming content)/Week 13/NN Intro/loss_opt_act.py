

# Теоретическое объяснение функций активации, функции потерь и оптимизатора с примерами из жизни

# === Функции активации ===
# torch.relu
# ! ReLU (Rectified Linear Unit) - одна из самых популярных функций активации в нейронных сетях.
# Пример из жизни:
# ? Представьте, что вы спортсмен, который оценивает свои результаты тренировок.
# * Если результат положительный (например, вы пробежали быстрее, чем раньше), вы его учитываете.
# * Если результат отрицательный (вы пробежали медленнее), вы просто игнорируете его.
# ! Формула ReLU: f(x) = max(0, x)
# * Положительные значения остаются без изменений, отрицательные заменяются на 0.
# ? Зачем это нужно?
# * ReLU делает модель нелинейной, позволяя ей обучаться сложным зависимостям.
# * Она также ускоряет обучение, так как проще вычисляется.

# === Функция потерь ===
# nn.CrossEntropyLoss
# ! CrossEntropyLoss - это функция потерь, которая используется для задач классификации.
# Пример из жизни:
# ? Представьте, что вы сдаёте тест, где каждый ответ может быть "правильным" или "неправильным".
# * Ваша цель - минимизировать количество неправильных ответов.
# * CrossEntropyLoss вычисляет "насколько плох" ваш ответ для каждого вопроса (класса).
#
# ? Как это работает:
# * Модель выдаёт логиты (числа, которые ещё не стали вероятностями).
# * Эти логиты преобразуются в вероятности через Softmax (например, вероятность 70% для цифры "3").
# * Функция потерь смотрит на вероятность истинного класса (например, цифры "3").
# * Чем ближе вероятность к 1, тем меньше потеря.
# ! Пример:
# * Логиты модели: [2.0, 1.5, -0.5]
# * Softmax преобразует их в вероятности: [0.65, 0.30, 0.05]
# * Если истинный класс - это "0" (первый класс), CrossEntropyLoss будет минимальной, когда вероятность = 1 (100%).

# === Оптимизатор ===
# optim.SGD
# ! SGD (Stochastic Gradient Descent) - это алгоритм оптимизации, который обновляет веса модели.
# Пример из жизни:
# ? Представьте, что вы учитесь готовить новое блюдо.
# * Ваша первая попытка может быть далека от идеала (много соли, мало специй).
# * Вы пробуете блюдо и понимаете, что нужно исправить (вычисляете "градиент").
# * В следующей попытке вы регулируете количество соли и специй (обновляете параметры).
# * Постепенно ваши действия становятся всё точнее, и вы готовите идеальное блюдо.
#
# ? Как работает SGD:
# 1. Вычисляет ошибку модели с помощью функции потерь.
# 2. Находит направление, в котором нужно изменить параметры (градиенты).
# 3. Обновляет параметры с учётом скорости обучения (learning rate):
#    новый_параметр = старый_параметр - lr * градиент
# ! Зачем нужен learning rate?
# * Он контролирует, насколько большие изменения вносить в каждый шаг.
# * Слишком большой - модель станет нестабильной.
# * Слишком маленький - обучение будет очень медленным.

# === Итоговая аналогия ===
# Представьте, что вы учитесь ездить на велосипеде:
# - **Функции активации (ReLU):** Это ваши рефлексы — вы реагируете только на полезные сигналы (например, дорогу впереди), игнорируя лишние (камни сбоку).
# - **Функция потерь (CrossEntropyLoss):** Это ваш учитель, который говорит, насколько хорошо вы справляетесь, основываясь на том, куда вы хотите поехать.
# - **Оптимизатор (SGD):** Это ваш мозг, который анализирует ошибки и корректирует ваши действия, чтобы постепенно научиться ехать ровно и уверенно.
